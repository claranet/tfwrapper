#!/usr/bin/env python3
"""Python wrapper for Terraform."""

import argparse
import logging
import os
import pickle
import platform
import random
import re
import shutil
import stat
import string
import subprocess
import tempfile
import time
import sys
import zipfile
from copy import deepcopy
from pathlib import Path

import boto3
import botocore
import colorlog
import jinja2
import requests
import yaml
from schema import Schema, SchemaError, Optional, Or
from termcolor import colored


def get_architecture():
    """Get system architecture name normalized for terraform."""
    platform_system = platform.machine()
    if 'arm' in platform_system:
        return 'arm'
    if platform_system in ('x86_64', 'darwin'):
        return 'amd64'
    return '386'


RC_OK = 0
RC_KO = 1
RC_UNK = 2
LIMIT_TERRAFORM_VERSION = 'v0.7.13'
LIMIT_GITHUB_RELEASES = 42
GITHUB_RELEASES = 'https://github.com/{}/releases'
ARCH_NAME = get_architecture()
PLATFORM_SYSTEM = platform.system().lower()
TFWRAPPER_DEFAULT_CONFIG = {
    'always_trigger_init': False,
    'pipe_plan_command': 'cat',
}

home_dir = str(Path.home())

# setup logging parameters
LOG_FORMAT = "{log_color}{levelname: <7}{reset} {purple}tfwrapper{reset} : {bold}{message}{reset}"
handler = colorlog.StreamHandler()
handler.setFormatter(colorlog.ColoredFormatter(LOG_FORMAT, style='{'))
logger = colorlog.getLogger()
logger.addHandler(handler)
logger.setLevel(logging.INFO)

stack_configuration_schema = Schema({
    Optional('state_configuration_name'): str,
    Optional('aws'): {
        'general': {
            'account': str,
            'region': str
        },
        'credentials': {
            'profile': str,
        }
    },
    Optional('azure'): {
        'general': {
            'mode': str,
            'subscription_id': str,
            'directory_id': str
        },
        Optional('credential'): {
            'profile': str
        }
    },
    Optional('gcp'): {
        'general': {
            'project': str,
            'mode': str
        },
        Optional('gke'): [
            {
                Or('zone', 'region'): str,
                'name': str
            }
        ]
    },
    'terraform': {
        'vars': {str: str},
        Optional('custom-providers'): {str: str},
    },
})


def error(message):
    """Raise a ValueError with an help message appended to the original message."""
    raise ValueError("{}\n\nUse -h to show the help message".format(message))


def load_wrapper_config(args):
    """Load wrapper config from args. Validate args and autodetect current stack."""
    # convert args to dict
    wrapper_config = deepcopy(vars(args))

    # detect confdir and rootdir locations
    parents_count = 0
    while parents_count < 5:
        if os.path.isdir('../' * parents_count + wrapper_config['confdir']):
            wrapper_config['confdir'] = '../' * parents_count + wrapper_config['confdir']
            logger.debug("Detected confdir at '{}'".format(wrapper_config['confdir']))
            break
        parents_count += 1

    if parents_count == 5:
        error("Cannot find configuration directory '{}' in this directory or above".format(wrapper_config['confdir']))

    wrapper_config['rootdir'] = os.path.dirname(os.path.abspath(wrapper_config['confdir']))
    logger.debug("Detected rootdir at '{}'".format(wrapper_config['rootdir']))

    # detect parent dirs
    count_up = 0
    count_down = parents_count

    # check wether we are in global environment
    if (os.path.basename(os.path.abspath('.')) == '_global' or
            os.path.basename(os.path.abspath('..')) == '_global' or
            wrapper_config['environment'] == 'global'):
        parents_list = ['account', 'environment', 'stack']
    else:
        parents_list = ['account', 'environment', 'region', 'stack']

    # detect dirs
    while count_down > 0:
        if wrapper_config[parents_list[count_up]] is None:
            wrapper_config[parents_list[count_up]] = os.path.basename(os.path.abspath('./' + '../' * (count_down - 1)))
        count_down -= 1
        count_up += 1

    for element in parents_list:
        if wrapper_config[element] is None:
            error("{} cannot be autodetected. Exiting...".format(element))

    # support both _global (fs) and global (param)
    if wrapper_config['environment'] == '_global':
        wrapper_config['environment'] = 'global'
    logger.debug("Detected environment '{}'".format(wrapper_config['environment']))

    # load wrapper config
    wrapper_config_file = os.path.join(wrapper_config['confdir'], 'config.yml')
    wrapper_config['config'] = TFWRAPPER_DEFAULT_CONFIG
    if os.path.exists(wrapper_config_file):
        with open(wrapper_config_file, 'r') as f:
            logger.debug("Loading wrapper config from '{}'".format(wrapper_config_file))
            w_config = yaml.safe_load(f)
            wrapper_config['config'].update(w_config)

    # load state configuration
    config_file = os.path.join(wrapper_config['confdir'], 'state.yml')
    with open(config_file, 'r') as f:
        logger.debug("Loading state config from '{}'".format(config_file))
        state_config = yaml.safe_load(f)

    wrapper_config['state'] = {}
    for config_type, config in state_config.items():
        config_name = config.get('name', config_type)
        wrapper_config['state'][config_name] = {
            'state_backend_type': config_type,
            # Azure configuration
            'state_subscription': state_config.get('azure', {}).get('general', {}).get('subscription_uid', None),
            'state_rg': state_config.get('azure', {}).get('general', {}).get('resource_group_name', None),
            'state_storage': state_config.get('azure', {}).get('general', {}).get('storage_account_name', None),
            # AWS configuration
            'state_account': state_config.get('aws', {}).get('general', {}).get('account', None),
            'state_region': state_config.get('aws', {}).get('general', {}).get('region', None),
            'state_profile': state_config.get('aws', {}).get('credentials', {}).get('profile', None)
        }

    # The default backend is the first in the list
    wrapper_config['default_state_backend_type'] = next(iter(state_config), None)

    return wrapper_config


def load_stack_config(confdir, account, environment, region, stack):
    """Load configuration from YAML file."""
    if environment == 'global':
        stack_config_file = '{}/{}_global_{}.yml'.format(confdir, account, stack)
    else:
        stack_config_file = '{}/{}_{}_{}_{}.yml'.format(confdir, account, environment, region, stack)

    with open(stack_config_file, 'r') as f:
        stack_config = yaml.safe_load(f)

    try:
        stack_configuration_schema.validate(stack_config)
    except SchemaError as e:
        logger.error('Configuration error in {} : {}'.format(stack_config_file, e))
        sys.exit(RC_KO)

    return stack_config


def _check_azure_auth(subscription_id):
    """Check if user is authenticated and have access to the subscription."""
    from azure.common.credentials import get_cli_profile
    try:
        profile = get_cli_profile()
        profile.get_raw_token(subscription=subscription_id)
        return True
    except Exception:
        return False


def _get_aws_session(session_cache_file, region, profile):
    """Get or create boto cached session."""
    if (os.path.isfile(session_cache_file) and
            time.time() - os.stat(session_cache_file).st_mtime < 2700):
        with open(session_cache_file, 'rb') as f:
            session_cache = pickle.load(f)
        session = boto3.Session(aws_access_key_id=session_cache['credentials'].access_key,
                                aws_secret_access_key=session_cache['credentials'].secret_key,
                                aws_session_token=session_cache['credentials'].token,
                                region_name=session_cache['region'])
    else:
        try:
            session = boto3.Session(profile_name=profile, region_name=region)
        except botocore.exceptions.ProfileNotFound:
            logger.error("Profile {} not found. Exiting...".format(profile))
            sys.exit(RC_KO)
        try:
            session_cache = {'credentials': session.get_credentials().get_frozen_credentials(),
                             'region': session.region_name}
        except botocore.exceptions.ParamValidationError:
            logger.error('Error validating authentication. Maybe the wrong MFA code ?')
            sys.exit(RC_KO)
        except Exception:
            logger.exception('Unknown error')
            sys.exit(RC_UNK)
        with os.fdopen(os.open(session_cache_file, os.O_WRONLY | os.O_CREAT,
                               mode=0o600), 'wb') as f:
            pickle.dump(session_cache, f, pickle.HIGHEST_PROTOCOL)
    return session


def _get_azure_session(session_cache_file, azure_subscription, azure_rg_profile, azure_storage):
    """Retrieve Azure storage access keys."""
    from azure.common.credentials import get_cli_profile
    from azure.mgmt.storage import StorageManagementClient

    if not _check_azure_auth(azure_subscription):
        logger.error('Error while getting Azure token, try logging you in with "az login" and '
                     'check that you are authorized on the Terraform state subscription.')
        sys.exit(RC_KO)

    profile = get_cli_profile()
    credentials, current_sub, tenant = profile.get_login_credentials(subscription_id=azure_subscription)

    storage_client = StorageManagementClient(credentials, azure_subscription)
    storage_keys = storage_client.storage_accounts.list_keys(azure_rg_profile, azure_storage)
    storage_keys = {v.key_name: v.value for v in storage_keys.keys}
    return storage_keys['key1']


def get_session(rootdir, account, region, profile, backend_type=None, conf=None):
    """Get/create session credentials for supported providers."""
    if backend_type == 'aws':
        # Get or create boto cached session.
        session_cache_file = '{}/.run/session_cache_{}_{}.pickle'.format(rootdir, account, profile)
        session = _get_aws_session(session_cache_file, region, profile)
    elif backend_type == 'azure':
        session_cache_file = '{}/.run/session_cache_{}_{}.pickle'.format(rootdir, conf['state_subscription'], conf['state_rg'])
        session = _get_azure_session(session_cache_file, conf['state_subscription'], conf['state_rg'], conf['state_storage'])
    else:
        session = None

    return session


def set_terraform_vars(vars):
    """Configure Terraform env."""
    for var, value in vars.items():
        if value is not None:
            os.environ['TF_VAR_{}'.format(var)] = str(value)


def get_stack_path(wrapper_config, local=False):
    """Return stack path."""
    rootdir = wrapper_config['rootdir']
    account = wrapper_config['account']
    environment = wrapper_config['environment']
    region = wrapper_config['region']
    stack = wrapper_config['stack']

    if local:
        if environment == 'global':
            stack_path = '{}/{}/_global/{}'.format(rootdir, account, stack)
        else:
            stack_path = '{}/{}/{}/{}/{}'.format(rootdir, account, environment, region, stack)
    else:
        if environment == 'global':
            stack_path = '{}/_global/{}'.format(account, stack)
        else:
            stack_path = '{}/{}/{}/{}'.format(account, environment, region, stack)

    return stack_path


def bootstrap(wrapper_config):
    """Bootstrap project."""
    rootdir = wrapper_config['rootdir']
    confdir = wrapper_config['confdir']
    stack_path = get_stack_path(wrapper_config, local=True)

    account = wrapper_config['account']
    environment = wrapper_config['environment']
    region = wrapper_config['region']
    stack = wrapper_config['stack']
    stack_config = load_stack_config(confdir, account, environment, region, stack)
    state_backend_name = stack_config.get('state_configuration_name', None)
    state_backend_type = (
        wrapper_config['state'].get(state_backend_name)['state_backend_type']
        if state_backend_name
        else wrapper_config.get('default_state_backend_type', None))

    # get stack cloud provider type
    stack_type = None
    for cloud_provider in ['aws', 'azure', 'gcp']:
        if cloud_provider in stack_config:
            stack_type = cloud_provider
            break

    if stack_type is None:
        logger.info('No cloud provider specified in configuration.')

    # bootstrap Terraform files from stack template
    if not os.path.isdir(stack_path):
        if wrapper_config.get('template') or stack_type:
            if wrapper_config.get('template'):
                template = wrapper_config['template'].lower()
            else:
                if environment == 'global':
                    template = '{}/global'.format(stack_type)
                else:
                    template = '{}/basic'.format(stack_type)

            shutil.copytree('{}/templates/{}'.format(rootdir, template), stack_path)
        else:
            logger.info('No template specified and no cloud provider defined in configuration, skipping.')
            os.makedirs(stack_path)

    # bootstrap state.tf from jinja2 template with a specified backend
    if not os.path.isfile('{}/state.tf'.format(stack_path)) and state_backend_type:
        client_name = stack_config['terraform']['vars'].get('client_name', account)

        template_path = '{}/templates/{}/common'.format(rootdir, state_backend_type)
        logger.debug("Using template path {}".format(template_path))

        jinja2_env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(template_path),
            lstrip_blocks=True,
            trim_blocks=True
        )

        state_conf = jinja2_env.get_template('state.tf.jinja2').render(
            client_name=client_name,
            account=account,
            environment=environment,
            region=region,
            stack=stack)

        with open('{}/state.tf'.format(stack_path), "w") as f:
            f.write(state_conf)

        logger.info('`state.tf` file generated with "{}" backend type configured.'.format(state_backend_type))
        logger.info('Please run `tfwrapper init` to initialize this stack.')


def search_on_github(repo, minor_version, patch_regex, patch, terraform=True):
    """Search release on github."""
    result = requests.get(GITHUB_RELEASES.format(repo))
    releases_count = 0
    while result.status_code == 200:
        releases = re.findall(r'<a href=\"/{}/releases/tag/.*\">(.*)</a>'.format(repo), result.text)
        releases_count += len(releases)
        for release in releases:
            if re.match(r'^v{}\.{}$'.format(minor_version, patch if patch else patch_regex), release):
                patch = patch or release.split('.')[-1]
                return patch
            # hard limit or it will takes too long time and terraform versions older than 0.7 do not respect naming convention
            if terraform and any(LIMIT_TERRAFORM_VERSION in r for r in releases):
                return None
            elif releases_count > LIMIT_GITHUB_RELEASES:
                return None
        if len(releases) < 1:
            # no more versions available
            break
        result = requests.get('{}?after={}'.format(GITHUB_RELEASES.format(repo), releases[-1:][0]))
    return None


def do_switchver(version):
    """
    Switch to desired terraform version if different from current one.

    :param version: string: desired terraform version
    """
    minor_version_regex = r'[0-9]+\.[0-9]+'
    patch_regex = r'[0-9]+((-alpha|-beta|-rc)[0-9]+)?'
    m = re.match(r'^(?P<minor>{})(\.(?P<patch>{}))?$'.format(minor_version_regex, patch_regex), version)
    if not m:
        error('The terraform version seems not correct, it should be a version number like "X.Y" or "X.Y.Z"')
    minor_version, patch = m.group('minor', 'patch')

    repo = 'hashicorp/terraform'
    patch = search_on_github(repo, minor_version, patch_regex, patch)

    if not patch:
        error("The release version {} for terraform does not exist".format(version))

    full_version = "{}.{}".format(minor_version, patch)

    # Getting current version
    try:
        p = subprocess.run(['terraform', '-v'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        current_version = re.match(r'^Terraform v({}\.{})'.format(minor_version_regex, patch_regex),
                                   p.stdout.decode('ascii')).group(1)
    except FileNotFoundError:
        current_version = 'not installed'

    if current_version == full_version:
        logger.debug("Terraform is already on version {}".format(full_version))
        return

    logger.warning("Current terraform version is {}, switching to version {}".format(current_version, full_version))

    version_path = os.path.expanduser(os.path.join('~/.terraform.d/versions', minor_version, full_version))
    tf_bin_path = os.path.join(version_path, 'terraform')
    local_tf_bin_path = os.path.join(os.path.dirname(__file__), 'terraform')
    os.makedirs(version_path, exist_ok=True)

    if not os.path.isfile(tf_bin_path):
        # Download and extract in user's home if needed
        logger.warning("Version does not exist locally, downloading it")
        handle, tmp_file = tempfile.mkstemp(prefix='terraform-', suffix='.zip')
        r = requests.get(
            'https://releases.hashicorp.com/terraform/{full_version}/terraform_{full_version}_{platform}_{arch}.zip'.format(
                full_version=full_version, platform=PLATFORM_SYSTEM, arch=ARCH_NAME),
            stream=True)
        with open(tmp_file, 'wb') as fd:
            for chunk in r.iter_content(chunk_size=128):
                fd.write(chunk)
        with zipfile.ZipFile(tmp_file, 'r') as zip:
            zip.extractall(path=version_path)
        # Permissions not preserved on extract https://bugs.python.org/issue15795
        os.chmod(tf_bin_path, os.stat(tf_bin_path).st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)
        os.remove(tmp_file)

    # Doing symlink
    if os.path.islink(local_tf_bin_path):
        os.remove(local_tf_bin_path)
    os.symlink(tf_bin_path, local_tf_bin_path)

    logger.warning("Switch done, current terraform version is {}".format(full_version))


def download_custom_provider(provider_name, provider_version):
    """Download Terraform custom provider."""
    logger.info("Checking custom Terraform provider '{}' at version '{}'".format(provider_name, provider_version))
    github_base = 'https://github.com/'
    github_endpoint = "{g}{p}".format(g=github_base, p=provider_name)

    r = requests.get(github_endpoint)
    if r.status_code != 200:
        error("The terraform provider {} does not exist ({})".format(provider_name, github_endpoint))

    m = re.match(r'^([0-9]+.[0-9]+).?([0-9]+)?(-[a-z]+)?$', provider_version)
    if not m:
        error('The provider version does not seem correct, it should be a version number like "X.Y", "X.Y.Z" or '
              '"X.Y.Z-custom"')
    minor_version, patch, custom = m.groups()

    patch = search_on_github(provider_name, minor_version, r'[0-9]+(-[a-z_-]+)?', patch, terraform=False)

    if not patch:
        error("The provider version '{}-{}' does not exist".format(provider_name, provider_version))

    full_version = "{}.{}".format(minor_version, patch)
    # Getting current version

    plugins_path = os.path.expanduser('~/.terraform.d/plugins/{platform}_{arch}'.format(platform=PLATFORM_SYSTEM, arch=ARCH_NAME))
    os.makedirs(plugins_path, exist_ok=True)
    provider_short_name = provider_name.split('/', 1)[1]
    bin_name = '{n}_{v}'.format(n=provider_short_name, v=full_version)
    tf_bin_path = os.path.join(plugins_path, '{n}_v{v}'.format(n=provider_short_name, v=full_version))

    if not os.path.isfile(tf_bin_path):
        # Download and extract in user's home if needed
        logger.warning("Provider version does not exist locally, downloading it")
        handle, tmp_file = tempfile.mkstemp(prefix='terraform-', suffix='.zip')
        r = requests.get(
            'https://github.com/{p}/releases/download/v{v}/{b}_{platform}_{arch}.zip'.format(
                p=provider_name, v=full_version, b=bin_name, platform=PLATFORM_SYSTEM, arch=ARCH_NAME),
            stream=True)
        with open(tmp_file, 'wb') as fd:
            for chunk in r.iter_content(chunk_size=128):
                fd.write(chunk)
        with zipfile.ZipFile(tmp_file, 'r') as zip:
            zip.extractall(path=plugins_path)
        # Permissions not preserved on extract https://bugs.python.org/issue15795
        os.chmod(tf_bin_path, os.stat(tf_bin_path).st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)
        os.remove(tmp_file)
        logger.info("Download done, current provider version is {}".format(full_version))
    else:
        logger.debug("Current provider version is already {}".format(full_version))


def adc_check_gke_credentials(adc_path, kubeconfig_path, gke_name, project, zone=None, region=None):
    """Provision kubeconfig for a given GKE instance using ADC."""
    cmd_env = deepcopy(os.environ)
    cmd_env['CLOUDSDK_CONTAINER_USE_APPLICATION_DEFAULT_CREDENTIALS'] = 'true'
    cmd_env['CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE'] = adc_path
    cmd_env['KUBECONFIG'] = kubeconfig_path

    logger.info('Looking for {} GKE credentials.'.format(gke_name))

    if zone is not None:
        command = ['gcloud', 'container', 'clusters', 'get-credentials', gke_name,
                   '--project', project,
                   '--zone', zone]
    elif region is not None:
        command = ['gcloud', 'container', 'clusters', 'get-credentials', gke_name,
                   '--project', project,
                   '--region', region]
    else:
        logger.error('You must specify a zone or region for {} GKE instance.'.format(gke_name))
        sys.exit(RC_KO)

    if not Path(kubeconfig_path).is_file():
        logger.warning('Could not find GKE credentials for {}, configuring new credentials.'.format(gke_name))

        try:
            subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True, env=cmd_env)
        except subprocess.CalledProcessError:
            logger.error('Could not configure {} GKE credentials.'.format(gke_name))
            sys.exit(RC_KO)
        logger.info('{} GKE credentials configured.'.format(gke_name))
    else:
        logger.info('Found {} GKE credentials.'.format(gke_name))


def run_terraform(action, wrapper_config):
    """Run Terraform command."""
    rootdir = wrapper_config['rootdir']

    tf_params = wrapper_config.get('tf_params')
    account = wrapper_config['account']
    environment = wrapper_config['environment']
    region = wrapper_config['region']
    stack = wrapper_config['stack']

    # support for custom parameters
    command = ["terraform", action]
    if tf_params is not None:
        if tf_params and tf_params[0] == '--':
            tf_params = tf_params[1:]
        command += tf_params

    working_dir = ('{}/{}/_global/{}'.format(rootdir, account, stack) if environment == 'global'
                   else '{}/{}/{}/{}/{}'.format(rootdir, account, environment, region, stack))

    cmd_env = deepcopy(os.environ)
    cmd_env['PATH'] = "{path}{sep}{old_path}".format(
        path=os.path.dirname(__file__), sep=os.pathsep, old_path=cmd_env.get('PATH', ''))

    pipe_plan_command = wrapper_config.get('pipe_plan_command') or wrapper_config['config'].get('pipe_plan_command')
    pipe_plan = action == "plan" and wrapper_config.get('pipe_plan') and pipe_plan_command
    stdout = pipe_plan and subprocess.PIPE or None
    with subprocess.Popen(command, cwd=working_dir, env=cmd_env, shell=False, stdout=stdout) as process:
        if pipe_plan:
            with subprocess.Popen(pipe_plan_command, cwd=working_dir, env=cmd_env,
                                  shell=True, stdin=process.stdout) as pipe_process:
                try:
                    pipe_process.communicate()
                except KeyboardInterrupt:
                    logger.warning('Received Ctrl+C')
                except:  # noqa
                    pipe_process.kill()
                    pipe_process.wait()
                    raise
                pipe_process.poll()
        try:
            process.communicate()
        except KeyboardInterrupt:
            logger.warning('Received Ctrl+C')
        except:  # noqa
            process.kill()
            process.wait()
            raise
        return process.poll()


def terraform_apply(wrapper_config):
    """Terraform apply wrapper function."""
    always_trigger_init = wrapper_config['config'].get('always_trigger_init', False)
    logger.debug("Checking 'always_trigger_init' option: {}".format(always_trigger_init))
    if always_trigger_init:
        logger.info('Init has been activated in config')
        terraform_init(wrapper_config)

    # do not force plan if unsafe
    if wrapper_config['unsafe']:
        return run_terraform('apply', wrapper_config)
    else:
        # plan config
        plan_path = '{}/.run/plan_{}'.format(wrapper_config['rootdir'],
                                             ''.join(random.choice(string.ascii_letters) for x in range(10)))
        plan_wrapper_config = deepcopy(wrapper_config)
        plan_wrapper_config['tf_params'][1:1] = ['-out', plan_path]
        plan_return_code = run_terraform('plan', plan_wrapper_config)

        # return Terraform return code if plan fails
        if plan_return_code > 0:
            return plan_return_code

        # ask for confirmation
        colored_account = colored(plan_wrapper_config['account'], 'yellow')
        colored_environment = colored(plan_wrapper_config['environment'], 'red')
        colored_region = colored(plan_wrapper_config['region'], 'blue')
        colored_stack = colored(plan_wrapper_config['stack'], 'green')

        if plan_wrapper_config['environment'] == 'global':
            env_msg = '''
    Account : {}
Environment : {}
      Stack : {}
'''.format(colored_account, colored_environment, colored_stack)
        else:
            env_msg = '''
    Account : {}
Environment : {}
     Region : {}
      Stack : {}
'''.format(colored_account, colored_environment, colored_region, colored_stack)

        print('\nDo you really want to apply this plan on the following stack ?\n',
              env_msg)
        apply_input = input("'yes' to confirm: ")

        try:
            if apply_input == 'yes':
                # apply config
                apply_wrapper_config = deepcopy(wrapper_config)
                apply_wrapper_config['tf_params'].append(plan_path)
                apply_return_code = run_terraform('apply', apply_wrapper_config)

                return apply_return_code
            else:
                logger.warning('Aborting apply.')
        finally:
            # delete plan
            os.remove(plan_path)


def terraform_console(wrapper_config):
    """Terraform console wrapper function."""
    return run_terraform('console', wrapper_config)


def terraform_destroy(wrapper_config):
    """Terraform destroy wrapper function."""
    return run_terraform('destroy', wrapper_config)


def terraform_fmt(wrapper_config):
    """Terraform fmt wrapper function."""
    return run_terraform('fmt', wrapper_config)


def terraform_force_unlock(wrapper_config):
    """Terraform force-unlock wrapper function."""
    return run_terraform('force-unlock', wrapper_config)


def terraform_get(wrapper_config):
    """Terraform get wrapper function."""
    # force update
    if not any('-update' in x for x in wrapper_config['tf_params']):
        wrapper_config['tf_params'][1:1] = ['-update']

    # call subcommand
    return run_terraform('get', wrapper_config)


def terraform_graph(wrapper_config):
    """Terraform graph wrapper function."""
    return run_terraform('graph', wrapper_config)


def terraform_import(wrapper_config):
    """Terraform import wrapper function."""
    return run_terraform('import', wrapper_config)


def terraform_init(wrapper_config):
    """Terraform init wrapper function."""
    return run_terraform('init', wrapper_config)


def terraform_output(wrapper_config):
    """Terraform output wrapper function."""
    return run_terraform('output', wrapper_config)


def terraform_plan(wrapper_config):
    """Terraform plan wrapper function."""
    always_trigger_init = wrapper_config['config'].get('always_trigger_init', False)
    logger.debug("Checking 'always_trigger_init' option: {}".format(always_trigger_init))
    if always_trigger_init:
        logger.info('Init has been activated in config')
        terraform_init(wrapper_config)
    return run_terraform('plan', wrapper_config)


def terraform_providers(wrapper_config):
    """Terraform providers wrapper function."""
    return run_terraform('providers', wrapper_config)


def terraform_refresh(wrapper_config):
    """Terraform refresh wrapper function."""
    return run_terraform('refresh', wrapper_config)


def terraform_show(wrapper_config):
    """Terraform show wrapper function."""
    return run_terraform('show', wrapper_config)


def terraform_state(wrapper_config):
    """Terraform state wrapper function."""
    return run_terraform('state', wrapper_config)


def terraform_taint(wrapper_config):
    """Terraform taint wrapper function."""
    return run_terraform('taint', wrapper_config)


def terraform_untaint(wrapper_config):
    """Terraform untaint wrapper function."""
    return run_terraform('untaint', wrapper_config)


def terraform_validate(wrapper_config):
    """Terraform validate wrapper function."""
    return run_terraform('validate', wrapper_config)


def terraform_version(wrapper_config):
    """Terraform version wrapper function."""
    return run_terraform('version', wrapper_config)


def switchver(wrapper_config):
    """Switch terraform version command."""
    version = wrapper_config.get('version')[0]
    do_switchver(version)


def main():
    """Execute tfwrapper."""
    # terraforms params doc
    tf_params_help = 'Any Terraform parameters after a "--" delimiter'

    # argparse
    parser = argparse.ArgumentParser(description='Terraform wrapper.')
    parser.add_argument("-d", "--debug",
                        action='store_true', default=False,
                        help="Enable debug output.")
    parser.add_argument('-c', '--confdir',
                        help='Configuration directory. Used to detect the project root. Defaults to conf.',
                        default='conf')
    parser.add_argument("-l", "--pipe-plan",
                        action='store_true', default=False,
                        help=("Pipe plan output to the command set in config"
                              " or passed in --pipe-plan-command argument (cat by default)."))
    parser.add_argument("--pipe-plan-command",
                        action='store', nargs='?',
                        help="Pipe plan output to the command of your choice set as argument inline value.")
    parser.add_argument('-a', '--account',
                        help='Target account. Autodetected if none is provided.',
                        nargs='?')
    parser.add_argument('-e', '--environment',
                        help='Target environment. Autodetected if none is provided.',
                        nargs='?')
    parser.add_argument('-r', '--region',
                        help='Target region. Autodetected if none is provided.',
                        nargs='?')
    parser.add_argument('-s', '--stack', help='Target stack. Autodetected if none is provided.',
                        nargs='?')
    parser.add_argument('-p', '--plugin-cache-dir', help='Plugins cache directory.',
                        default='{}/.terraform.d/plugin-cache'.format(home_dir))

    subparsers = parser.add_subparsers(dest='subcommand', help='subcommands')

    parser_apply = subparsers.add_parser('apply', help='terraform apply')
    parser_apply.set_defaults(func=terraform_apply)
    parser_apply.add_argument('-u', '--unsafe',
                              help='Do not force plan and human interaction before apply.',
                              action='store_true', default=False)
    parser_apply.add_argument("-l", "--pipe-plan",
                              action='store_true', default=False,
                              help=("Pipe plan output to the command set in config"
                                    " or passed in --pipe-plan-command argument (cat by default)."))
    parser_apply.add_argument("--pipe-plan-command",
                              action='store', nargs='?',
                              help="Pipe plan output to the command of your choice set as argument inline value.")
    parser_apply.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_console = subparsers.add_parser('console', help='terraform console')
    parser_console.set_defaults(func=terraform_console)
    parser_console.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_destroy = subparsers.add_parser('destroy', help='terraform destroy')
    parser_destroy.set_defaults(func=terraform_destroy)
    parser_destroy.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_fmt = subparsers.add_parser('fmt', help='terraform fmt')
    parser_fmt.set_defaults(func=terraform_fmt)
    parser_fmt.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_force_unlock = subparsers.add_parser('force-unlock', help='terraform force-unlock')
    parser_force_unlock.set_defaults(func=terraform_force_unlock)
    parser_force_unlock.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_get = subparsers.add_parser('get', help='terraform get')
    parser_get.set_defaults(func=terraform_get)
    parser_get.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_graph = subparsers.add_parser('graph', help='terraform graph')
    parser_graph.set_defaults(func=terraform_graph)
    parser_graph.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_import = subparsers.add_parser('import', help='terraform import')
    parser_import.set_defaults(func=terraform_import)
    parser_import.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_init = subparsers.add_parser('init', help='terraform init')
    parser_init.set_defaults(func=terraform_init)
    parser_init.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_output = subparsers.add_parser('output', help='terraform output')
    parser_output.set_defaults(func=terraform_output)
    parser_output.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_plan = subparsers.add_parser('plan', help='terraform plan')
    parser_plan.set_defaults(func=terraform_plan)
    parser_plan.add_argument("-l", "--pipe-plan",
                             action='store_true', default=False,
                             help=("Pipe plan output to the command set in config"
                                   " or passed in --pipe-plan-command argument (cat by default)."))
    parser_plan.add_argument("--pipe-plan-command",
                             action='store', nargs='?',
                             help="Pipe plan output to the command of your choice set as argument inline value.")
    parser_plan.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_providers = subparsers.add_parser('providers', help='terraform providers')
    parser_providers.set_defaults(func=terraform_providers)
    parser_providers.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_refresh = subparsers.add_parser('refresh', help='terraform refresh')
    parser_refresh.set_defaults(func=terraform_refresh)
    parser_refresh.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_show = subparsers.add_parser('show', help='terraform show')
    parser_show.set_defaults(func=terraform_show)
    parser_show.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_state = subparsers.add_parser('state', help='terraform state')
    parser_state.set_defaults(func=terraform_state)
    parser_state.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_taint = subparsers.add_parser('taint', help='terraform taint')
    parser_taint.set_defaults(func=terraform_taint)
    parser_taint.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_untaint = subparsers.add_parser('untaint', help='terraform untaint')
    parser_untaint.set_defaults(func=terraform_untaint)
    parser_untaint.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_validate = subparsers.add_parser('validate', help='terraform validate')
    parser_validate.set_defaults(func=terraform_validate)
    parser_validate.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_version = subparsers.add_parser('version', help='terraform version')
    parser_version.set_defaults(func=terraform_version)
    parser_version.add_argument('tf_params', nargs=argparse.REMAINDER, help=tf_params_help)

    parser_bootstrap = subparsers.add_parser('bootstrap', help='bootstrap configuration')
    parser_bootstrap.set_defaults(func=bootstrap)
    parser_bootstrap.add_argument('template', nargs='?', help='template to use during bootstrap', default=None)

    parser_switchver = subparsers.add_parser('switchver', help='switch terraform version')
    parser_switchver.set_defaults(func=switchver)
    parser_switchver.add_argument('version', nargs=1, help='terraform version to use')

    args = parser.parse_args()

    if args.debug:
        logger.setLevel(logging.DEBUG)

    # process args
    try:
        wrapper_config = load_wrapper_config(args)
    except ValueError as e:
        logger.error(e)
        sys.exit(RC_KO)
    except Exception:
        logger.exception('Unknown error')
        sys.exit(RC_UNK)

    if args.subcommand not in ('switchver', 'version',):
        # load config
        stack_config = load_stack_config(wrapper_config['confdir'],
                                         wrapper_config['account'],
                                         wrapper_config['environment'],
                                         wrapper_config['region'],
                                         wrapper_config['stack'])

        # get sessions
        state_backend_name = stack_config.get('state_configuration_name', None)
        state_config = (
            wrapper_config['state'].get(state_backend_name)
            if state_backend_name
            else next(iter(wrapper_config['state'].values())))
        state_backend_type = state_config['state_backend_type']

        logger.info('Getting state session ({})'.format(state_backend_name or state_backend_type))
        state_session = get_session(wrapper_config['rootdir'],
                                    state_config.get('state_account'),
                                    state_config.get('state_region'),
                                    state_config.get('state_profile'),
                                    state_backend_type, state_config)

        if state_backend_type == 'aws':
            # set AWS state centralization environment variables
            state_credentials = state_session.get_credentials().get_frozen_credentials()
            os.environ['AWS_ACCESS_KEY_ID'] = state_credentials.access_key
            os.environ['AWS_SECRET_ACCESS_KEY'] = state_credentials.secret_key
            if state_credentials.token:
                os.environ['AWS_SESSION_TOKEN'] = state_credentials.token
            logger.info('AWS state backend initialized.')
        elif state_backend_type == 'azure':
            # set Azure state centralization environment variables
            os.environ['ARM_ACCESS_KEY'] = state_session
            os.environ['TF_VAR_azure_state_access_key'] = state_session
            logger.info('Azure state backend initialized.')
        else:
            logger.info('Unsupported state backend type "{}". Let terraform handle with its default behavior.'.
                        format(state_backend_type))

        terraform_vars = stack_config['terraform']['vars']
        terraform_vars['environment'] = wrapper_config['environment']
        terraform_vars['stack'] = wrapper_config['stack']

        if 'aws' in stack_config:
            logger.info('Getting stack session')
            stack_session = get_session(wrapper_config['rootdir'],
                                        stack_config['aws']['general']['account'],
                                        stack_config['aws']['general']['region'],
                                        stack_config['aws']['credentials']['profile'],
                                        'aws')

            # set terraform environment variables for AWS Stack
            stack_credentials = stack_session.get_credentials().get_frozen_credentials()
            terraform_vars['account'] = wrapper_config['account']
            terraform_vars['region'] = wrapper_config['region']
            terraform_vars['aws_access_key'] = stack_credentials.access_key
            terraform_vars['aws_secret_key'] = stack_credentials.secret_key
            terraform_vars['aws_token'] = stack_credentials.token

        # GCP/GKE support
        if 'gcp' in stack_config:
            gcp_auth_mode = stack_config['gcp']['general'].get('mode')
            if gcp_auth_mode.lower() == 'adc-user':
                # In this mode we are trying to use ADC credentials of type authorized_user.
                # The rational is to facilitate interactive usage from a local dev environment.
                # We assume that the user is using the same identity for all projects.
                # GKE access, if required, is configured using the same credentials with per-stack kuebconfig files.

                logger.info('Looking for GCP user Application Default Credentials.')
                try:
                    command = ['gcloud', 'auth', 'application-default', 'print-access-token']
                    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
                except FileNotFoundError:
                    logger.error('Please make sure that gcloud is available on this system.')
                    sys.exit(RC_KO)
                except subprocess.CalledProcessError:
                    logger.error('Could not find valid user Application Default Credentials. Please run: '
                                 'gcloud auth application-default login')
                    sys.exit(RC_KO)
                logger.info('Found GCP user Application Default Credentials.')

                if 'gke' in stack_config['gcp']:
                    project = stack_config['gcp']['general']['project']

                    for cluster in stack_config['gcp']['gke']:
                        gke_name = cluster['name']
                        adc_path = os.path.join(os.path.abspath(home_dir), '.config/gcloud/application_default_credentials.json')
                        kubeconfig_path = '{}/.run/{}_{}_{}_{}_{}.kubeconfig'.format(wrapper_config['rootdir'],
                                                                                     wrapper_config['account'],
                                                                                     wrapper_config['environment'],
                                                                                     wrapper_config['region'],
                                                                                     wrapper_config['stack'],
                                                                                     gke_name)

                        if 'zone' in cluster:
                            adc_check_gke_credentials(adc_path, kubeconfig_path, gke_name, project, zone=cluster['zone'])
                        elif 'region' in cluster:
                            adc_check_gke_credentials(adc_path, kubeconfig_path, gke_name, project, region=cluster['region'])
                        else:
                            logger.error('You must specify a zone or region for {} GKE instance.'.format(gke_name))
                            sys.exit(RC_KO)

                        terraform_vars['gke_kubeconfig_{}'.format(gke_name)] = kubeconfig_path
            else:
                logger.error('Sorry, tfwrapper only supports user Application Default Credentials right now.')
                sys.exit(RC_KO)

        # Add support Azure
        if 'azure' in stack_config:
            if 'client_name' not in terraform_vars:
                terraform_vars['client_name'] = wrapper_config['account']
            terraform_vars['azurerm_region'] = wrapper_config['region']  # Kept for retro-compat
            terraform_vars['azure_region'] = wrapper_config['region']
            terraform_vars['azure_subscription_id'] = stack_config['azure']['general']['subscription_id']

            az_login_mode = stack_config['azure']['general'].get('mode', 'user')
            if az_login_mode.lower() == 'user':
                logger.info('Using Azure user mode')

                directory_id = stack_config['azure']['general'].get('directory_id', None)
                terraform_vars['azure_tenant_id'] = stack_config['azure']['general'].get('tenant_id', directory_id)
                if not terraform_vars['azure_tenant_id']:
                    logger.error('Please set the `azure.general.directory_id` variable in your stack configuration.')
                    sys.exit(RC_KO)

                if not _check_azure_auth(terraform_vars['azure_subscription_id']):
                    logger.error('Error while getting Azure token, try logging you in with "az login" '
                                 'and  check that you are authorized on this subscription.')
                    sys.exit(RC_KO)
            elif az_login_mode.lower() in ['sp', 'serviceprincipal', 'service_principal']:
                logger.info('Using Azure Service Principal mode')

                azure_config = open(os.path.abspath(home_dir) + '/.azurerm/config.yml')
                load_azure_config = yaml.load(azure_config)
                if load_azure_config is None:
                    logger.error('Please configure your ~/.azurerm/config.yml configuration file')
                    sys.exit(RC_KO)
                profile = stack_config['azure']['credential']['profile']
                if profile not in load_azure_config.keys():
                    logger.error('Cannot find "{}" profile in your ~/.azurerm/config.yml configuration file'.format(profile))
                    sys.exit(RC_KO)

                terraform_vars['azure_tenant_id'] = load_azure_config[profile]['tenant_id']

                os.environ['ARM_CLIENT_ID'] = load_azure_config[profile]['client_id']
                os.environ['ARM_CLIENT_SECRET'] = load_azure_config[profile]['client_secret']
            else:
                logger.error('Please use a correct Azure authentication mode ("user" or "service_principal") '
                             'in your stack YAML configuration.')
                sys.exit(RC_KO)

        set_terraform_vars(terraform_vars)
        os.environ['TF_PLUGIN_CACHE_DIR'] = wrapper_config['plugin_cache_dir']

    returncode = None

    if hasattr(args, 'func'):
        # check terraform version
        if args.subcommand not in ('providers', 'switchver', 'version',):
            tf_version = stack_config['terraform']['vars'].get('version')
            if tf_version:
                do_switchver(tf_version)
        # do we need a custom provider ?
        if args.subcommand in ["init", "bootstrap"]:
            for provider, provider_version in stack_config['terraform'].get('custom-providers', {}).items():
                download_custom_provider(provider, provider_version)

        # call subcommand
        returncode = args.func(wrapper_config)
    else:
        parser.print_help(file=sys.stderr)

    if returncode is not None:
        sys.exit(returncode)
    else:
        sys.exit(RC_OK)


if __name__ == "__main__":
    main()
